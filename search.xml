<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Large-Language-Model For Math</title>
      <link href="/2023/06/03/Survey4MATH/"/>
      <url>/2023/06/03/Survey4MATH/</url>
      
        <content type="html"><![CDATA[<h1 id="Large-Language-Model-For-Math"><a href="#Large-Language-Model-For-Math" class="headerlink" title="Large-Language-Model For Math"></a>Large-Language-Model For Math</h1><p>让LLM大模型解决数学问题！ — #TODO<br><span id="more"></span></p><p>由于最近在做相关方向的科研，将阅读的论文整理在这里。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">💡 阅读记录格式:</span><br><span class="line"></span><br><span class="line">### Pretraining</span><br><span class="line"></span><br><span class="line">1. which foundation models are based on?</span><br><span class="line">2. what tokenizers are adopted?</span><br><span class="line">3. which datasets are collected specific for &quot;math&quot;?</span><br><span class="line">4. what types of pre-processing methods are introduced?</span><br><span class="line">5. other information that  you think is important</span><br><span class="line"></span><br><span class="line">### Fine-tuning</span><br><span class="line"></span><br><span class="line">1. which datasets are used?</span><br><span class="line">2. what types of pre-processing methods are used?</span><br><span class="line"></span><br><span class="line">### Evaluation</span><br><span class="line"></span><br><span class="line">1. which datasets are used?</span><br><span class="line">2. what type of pre-processing methods are used?</span><br><span class="line">3. what evaluation metrics are used?</span><br></pre></td></tr></table></figure><h3 id="阅读的论文列表："><a href="#阅读的论文列表：" class="headerlink" title="阅读的论文列表："></a>阅读的论文列表：</h3><p><a href="https://www.notion.so/Training-Verifiers-to-Solve-Math-Word-Problems-db6822f1cf9b45ad960b1dbb574ab4b8">Training Verifiers to Solve Math Word Problems</a></p><p><a href="https://www.notion.so/Solving-Quantitative-Reasoning-Problems-with-Language-Models-19b339fda58246fbadb22166a78b6ffd">Solving Quantitative Reasoning Problems with Language Models</a></p><p><a href="https://www.notion.so/MathPrompter-Mathematical-Reasoning-using-Large-Language-Models-92db0f041ac94c53884e799948af207d">MathPrompter: Mathematical Reasoning using Large Language Models</a></p><p><a href="https://www.notion.so/PAL-Program-aided-Language-Models-ddaecc337f414b8ea37985999bdec23c">PAL: Program-aided Language Models</a></p><p><a href="https://www.notion.so/Specializing-Smaller-Language-Models-towards-Multi-Step-Reasoning-6e8af05836f243058cc8d2374162c2c6">Specializing Smaller Language Models towards Multi-Step Reasoning</a></p>]]></content>
      
      
      <categories>
          
          <category> llm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DeepLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Image2Poem</title>
      <link href="/2023/05/23/Image2Poem/"/>
      <url>/2023/05/23/Image2Poem/</url>
      
        <content type="html"><![CDATA[<h1 id="Image-to-Poem"><a href="#Image-to-Poem" class="headerlink" title="Image-to-Poem"></a>Image-to-Poem</h1><p>此情此景，何不吟诗一首？Image-to-Poem帮你完成！<br><span id="more"></span></p><p>项目链接：<br><a href="https://github.com/weiji-Feng/Image2Poem">https://github.com/weiji-Feng/Image2Poem</a></p><p>9.28之前可能会忙于升学，本项目暂不更新。希望可以在10.31号之前完成这个项目的全部功能。</p><h2 id="1-项目介绍"><a href="#1-项目介绍" class="headerlink" title="1. 项目介绍"></a>1. 项目介绍</h2><p>图像生成古诗(Image to Poem)，旨在为给定的图像自动生成符合图像内容的古诗句。</p><p>使用对比学习预训练的CLIP模型拥有良好的迁移应用和zero-shot能力，是打通图像-文本多模态的重要模型之一。 本项目使用<a href="https://github.com/openai/CLIP">CLIP模型</a>生成古诗意象关键词向量和图像向量。</p><p>初始版本的生成方法为：搜集一个古诗词意象关键词数据集(close-set)，然后通过text-encoder(图1.右) 生成对应的关键词向量。对给定的一张图像，同样通过Image-encoder即可得到图像向量。比较图像向量和每个关键词向量的余弦相似度，可以得到top-k个相关关键词。将关键词送入语言模型，自动生成一首诗。</p><p>这种提取关键词的操作将<strong>会大大损失图像的语义信息</strong>，进而影响语言模型的古诗生成。但由于图像-古诗对数据集非常匮乏，我们很难&lt;/u&gt;像Dalle模型一样&lt;/u&gt;，直接将CLIP模型Image-encoder的输出向量，通过一个MappingNet(在DALLE-2中就是prior模块)送入解码器(语言模型)。所以如果有更好的想法欢迎指点。<br><img src="https://github.com/openai/CLIP/raw/main/CLIP.png" alt="img.png"></p><p>由于古诗的特殊性，本项目重头训练了一个用于生成古诗文的Language Model，尝试了T5 model（223M）和GPT2 model（118M），现公开该预训练模型以供大家娱乐。</p><p>以上模型均可通过调用 <a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a> 的<code>transformers</code>导入。</p><h2 id="2-引用和致谢"><a href="#2-引用和致谢" class="headerlink" title="2. 引用和致谢"></a>2. 引用和致谢</h2><p>在项目完成期间，我参考并使用了以下项目，这里表示感谢！ </p><ul><li>数据集来源：<a href="https://github.com/THUNLP-AIPoet/CCPM">https://github.com/THUNLP-AIPoet/CCPM</a></li><li>CLIP预训练模型来源： <a href="https://github.com/OFA-Sys/Chinese-CLIP">https://github.com/OFA-Sys/Chinese-CLIP</a></li><li>GPT2预训练部分代码：<a href="https://github.com/Morizeyao/GPT2-Chinese">https://github.com/Morizeyao/GPT2-Chinese</a></li></ul><h2 id="3-使用说明和生成样例"><a href="#3-使用说明和生成样例" class="headerlink" title="3. 使用说明和生成样例"></a>3. 使用说明和生成样例</h2><h3 id="安装依赖库"><a href="#安装依赖库" class="headerlink" title="安装依赖库"></a>安装依赖库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio</span><br><span class="line">pip install transformers</span><br><span class="line">pip install tqdm matplotlib</span><br></pre></td></tr></table></figure><p>如果希望尝试预训练语言模型, 建议安装<code>torch+cudaxx.x</code>的GPU版本。</p><h3 id="快速体验古诗生成"><a href="#快速体验古诗生成" class="headerlink" title="快速体验古诗生成"></a>快速体验古诗生成</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python img2poem.py --image_path ./datasets/images/feiliu.jpg --model_type T5 --model_path ./config/t5_config</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><code>--image_path</code>: 图片所在位置</li><li><code>--model_type</code>: 模型名称,目前可选用’T5’,’GPT2’</li><li><code>--model_path</code>: 模型所在文件夹</li></ul><h3 id="生成样例"><a href="#生成样例" class="headerlink" title="生成样例"></a>生成样例</h3><p><img src="https://github.com/weiji-Feng/Image2Poem/raw/main/datasets/images/feiliu.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">飞鹤度湖山，青松半掩关。水林昼景凤，诸君自有闲。</span><br><span class="line">白苹洲渚流，丹青未有人。水林壑夜深，乱峰高几重。 </span><br><span class="line">仙人问道踪，壑深自坐禅。丹青一片云，月随风水林。   </span><br><span class="line">不见青林路，却忆庐陵西。老松犹未分，钟山水似难。</span><br><span class="line">飞鹤度湖山，青松半掩关。丹壑千人在，犹记林水心。</span><br></pre></td></tr></table></figure><p><img src="https://github.com/weiji-Feng/Image2Poem/raw/main/datasets/images/chun.jpg" alt="image-20230408233621777" style="zoom:30%;" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">青碧绕瑶池，碧峰回九关。晚风吹画船，映水长成芳。</span><br><span class="line">犹自在藏新，不知是旧人。暮天三百年，桃源一片春。</span><br><span class="line">数年三两枝，却羡玉龙飞。桃源水一津，斜晖又一年。</span><br><span class="line">千骑鹤归飞，一曲茅亭去。天上桃源路，玉龙归白杳。</span><br><span class="line">相逢一笑飞，知有桃源人。何如写玉龙，斜晖送晚风</span><br></pre></td></tr></table></figure><p><img src="https://github.com/weiji-Feng/Image2Poem/raw/main/datasets/images/pubu.jpg" alt="image-20230408233621777" style="zoom:90%;" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">清江起玉龙，时听瀑布声。飞曲满游子，一生天上流。</span><br><span class="line">萧然见山来，却恐归来晚。时见布泉飞，锦囊深掩门。</span><br><span class="line">时有一花村，俗人如此山。月溪风乱鸣，时有瀑布还。</span><br><span class="line">月明闲送风，瀑布飞仙雪。人间几度林，锦衣还说天。 </span><br><span class="line">谁人识此中，布泉老客行。月满江来路，不须频为谁。</span><br></pre></td></tr></table></figure><h2 id="4-一些解释"><a href="#4-一些解释" class="headerlink" title="4. 一些解释"></a>4. 一些解释</h2><ul><li>对于当前项目的评价<blockquote><p>提取关键词进行古诗生成是一个<strong>损失信息</strong>的过程，尤其是将图像映射到关键词的操作，损失了图像原本的语义(例如只能识别人，而不知道人在做什么)。所以效果上来看仍然差强人意。</p><p>没有给模型一些关于韵律、题材、体裁等的设定，导致不够专业。</p></blockquote></li><li><p>可不可以使用自己的古诗数据集尝试预训练？</p><blockquote><p>可以，不过由于CCPM数据集是<code>.json</code>文件格式,导入方式与<code>.txt</code>不同。所以在<code>datasets.py</code>文件里你需要重新写一下有关文件导入的部分。并且由于预训练方法多样，你也可以修改预训练时的一些策略。</p></blockquote></li><li><p>项目的预训练方法是什么？</p><blockquote><p>首先对于GPT2模型，常规预训练方法就是自回归，本项目尝试了mask关键词的方法，例如：</p><p><code>[CLS]关键词：明月 故乡 [EOS] 举头望明月，低头思故乡[SEP]</code> =&gt; <code>[CLS]关键词：明月 故乡 [EOS] 举头望[MASK][MASK]，低头思[MASK][MASK][SEP]</code></p><p>然后我额外对这些mask token的预测准确率进行了计算，加入了损失函数中。</p><p>对于T5模型，由于是encoder-decoder架构，我使用下列格式创建数据：</p><p>x = <code>[CLS]关键词：红豆 南国 发 愿君[EOS][SEP]</code>, y = <code>[CLS]红豆生南国[EOS][SEP]</code></p><p>x = <code>[CLS]关键词：红豆 南国 发 愿君[EOS]红豆生南国[EOS][SEP]</code>, y = <code>[CLS]秋来发故枝[EOS][SEP]</code></p><p>x = <code>[CLS]关键词：红豆 南国 发 愿君[EOS]红豆生南国[EOS]秋来发故枝[EOS][SEP]</code>, y = <code>[CLS]愿君多采撷[EOS][SEP]</code></p><p>x = <code>[CLS]关键词：红豆 南国 发 愿君[EOS]红豆生南国[EOS]秋来发故枝[EOS]愿君多采撷[EOS][SEP]</code>, y = <code>[CLS]此物最相思[EOS][SEP]</code></p></blockquote></li><li><p>通过什么方式进行图像生成古诗？未来有什么进一步更新的方法？</p><blockquote><p>现在的实现比较简单，就是先搜集一个闭环的关键词数据集(<code>keyword.txt</code>)，然后使用CLIP对图像和所有关键词进行编码，计算它们之间的相似度，取相似度最高的K个关键词，然后放置于语言模型进行生成。</p><p>由于<code>图像-古诗对</code>数据集非常匮乏，似乎暂时做不到删去这个闭环关键词数据集。未来如果有充足的数据集，我会使用<code>CLIP-MappingNet-T5/GPT2</code>的模型架构进行训练，例如下图的<a href="https://arxiv.org/pdf/2111.09734.pdf">CLIPCap</a>架构：</p><p><img src="https://cdn-images-1.medium.com/max/800/1*8RLzDpMfi6sLScqx2SguaA.png" alt=""></p></blockquote></li></ul><p>未来有古诗生成图像的想法，待进一步更新。现有的可以进行古诗生成图像的项目有：<a href="https://huggingface.co/IDEA-CCNL/Taiyi-Diffusion-532M-Nature-Chinese">https://huggingface.co/IDEA-CCNL/Taiyi-Diffusion-532M-Nature-Chinese</a></p>]]></content>
      
      
      <categories>
          
          <category> multi-modal </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DeepLearning </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
